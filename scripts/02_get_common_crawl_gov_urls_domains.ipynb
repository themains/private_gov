{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096ca2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import logging\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict, Union\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from urllib.parse import quote\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e26daf-c968-4dc1-b54a-5ae838aa8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonCrawlScraper:\n",
    "    def __init__(self, base_index: str = \"CC-MAIN-2024-30\"):\n",
    "        self.base_url = f\"https://index.commoncrawl.org/{base_index}-index\"\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # Set up logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "    \n",
    "    def fetch_page(self, search_term: str, page: int) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Fetch a single page of results for a search term.\n",
    "        \n",
    "        Args:\n",
    "            search_term: Term to search for (e.g., \"*.gov\")\n",
    "            page: Page number to fetch\n",
    "            \n",
    "        Returns:\n",
    "            List of result dictionaries or None if page is invalid.\n",
    "        \"\"\"\n",
    "        encoded_term = quote(search_term)\n",
    "        url = f\"{self.base_url}?url={encoded_term}&output=json&page={page}\"\n",
    "        logging.info(f\"Fetching page {page} for {search_term}\")\n",
    "        try:\n",
    "            response = self.session.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            results = []\n",
    "            for line in response.text.strip().split('\\n'):\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    if 'message' in data and 'invalid' in data['message'].lower():\n",
    "                        logging.info(f\"Reached end of valid pages at page {page} for {search_term}\")\n",
    "                        return None\n",
    "                    results.append(data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logging.warning(f\"Could not parse line on page {page} for {search_term}: {e}\")\n",
    "                    continue\n",
    "            logging.info(f\"Page {page} returned {len(results)} results.\")\n",
    "            return results\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Error fetching page {page} for {search_term}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def scrape_pattern(self, country: str, pattern: str, start_page: int = 0, \n",
    "                      delay: float = 1.0) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Scrape all pages for a single search pattern.\n",
    "        \n",
    "        Args:\n",
    "            country: Country label (e.g., \"United States\")\n",
    "            pattern: Domain pattern to search (e.g., \"*.gov\")\n",
    "            start_page: Page number to start from\n",
    "            delay: Base delay between requests in seconds\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing results for this pattern.\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        page = start_page\n",
    "        pages_scraped = 0\n",
    "        \n",
    "        logging.info(f\"Starting scrape for {country} pattern: {pattern}\")\n",
    "        while True:\n",
    "            results = self.fetch_page(pattern, page)\n",
    "            if not results:\n",
    "                logging.info(f\"No more results for {country} pattern {pattern} after page {page}.\")\n",
    "                break\n",
    "            for result in results:\n",
    "                result['country'] = country\n",
    "                result['pattern'] = pattern\n",
    "            all_results.extend(results)\n",
    "            pages_scraped += 1\n",
    "            logging.info(f\"Scraped page {page} for {country} pattern {pattern} ({len(results)} results). Total pages scraped: {pages_scraped}\")\n",
    "            \n",
    "            sleep_time = delay + random.uniform(0, delay)\n",
    "            logging.info(f\"Sleeping for {sleep_time:.2f} seconds before next page request.\")\n",
    "            time.sleep(sleep_time)\n",
    "            page += 1\n",
    "        \n",
    "        logging.info(f\"Finished scraping pattern {pattern} for {country}. Total results: {len(all_results)}\")\n",
    "        return pd.DataFrame(all_results) if all_results else pd.DataFrame()\n",
    "    \n",
    "    def scrape_all(self, search_terms: Dict[str, Union[str, List[str]]], \n",
    "               delay: float = 1.0) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Scrape all pages for multiple countries and their patterns.\n",
    "\n",
    "        Args:\n",
    "            search_terms: Dictionary mapping countries to patterns, \n",
    "                          e.g., {\"USA\": [\"*.gov\", \"*.fed.us\"], \"Canada\": [\"*.gc.ca\"]}\n",
    "            delay: Base delay between requests in seconds.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame containing all results.\n",
    "        \"\"\"\n",
    "        all_dfs = []\n",
    "        for country, patterns in search_terms.items():\n",
    "            if isinstance(patterns, str):\n",
    "                patterns = [patterns]\n",
    "            for pattern in patterns:\n",
    "                safe_pattern = pattern.replace('*', 'ALL').replace('.', '_')\n",
    "                filename = f'commoncrawl_{country.lower()}_{safe_pattern}_results.parquet'\n",
    "                if os.path.exists(filename):\n",
    "                    logging.info(f\"File {filename} already exists; skipping scrape for {country} pattern {pattern}\")\n",
    "                    continue\n",
    "\n",
    "                logging.info(f\"Starting scrape for {country} pattern: {pattern}\")\n",
    "                try:\n",
    "                    df = self.scrape_pattern(country, pattern, delay=delay)\n",
    "                    if not df.empty:\n",
    "                        all_dfs.append(df)\n",
    "                        df.to_parquet(filename, index=False)\n",
    "                        logging.info(f\"Saved intermediate results for {country} pattern {pattern} to {filename}\")\n",
    "                    else:\n",
    "                        logging.info(f\"No data found for {country} pattern {pattern}.\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {country} pattern {pattern}: {e}\")\n",
    "                    continue\n",
    "        if all_dfs:\n",
    "            final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "            final_filename = \"commoncrawl_all_results.parquet\"\n",
    "            final_df.to_parquet(final_filename, index=False)\n",
    "            logging.info(f\"Scrape complete. Total results: {len(final_df)}. Saved final results to {final_filename}\")\n",
    "\n",
    "            summary = final_df.groupby(['country', 'pattern']).size().reset_index(name='count')\n",
    "            logging.info(\"Summary of results by country and pattern:\")\n",
    "            logging.info(summary.to_string(index=False))\n",
    "            return final_df\n",
    "        else:\n",
    "            logging.info(\"No results were scraped.\")\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb308d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_domains = {\n",
    "    # North America\n",
    "    \"United States\": [\"*.gov\", \"*.mil\"],\n",
    "    \"Canada\": [\"*.gc.ca\", \"*.canada.ca\"],\n",
    "    \"Mexico\": \"*.gob.mx\",\n",
    "    \n",
    "    # Caribbean\n",
    "    \"Jamaica\": \"*.gov.jm\",\n",
    "    \"Trinidad and Tobago\": \"*.gov.tt\",\n",
    "    \"Barbados\": \"*.gov.bb\",\n",
    "    \"Bahamas\": \"*.gov.bs\",\n",
    "    \"Dominican Republic\": \"*.gob.do\",\n",
    "    \n",
    "    # Central America\n",
    "    \"Costa Rica\": \"*.go.cr\",\n",
    "    \"Panama\": \"*.gob.pa\",\n",
    "    \"Guatemala\": \"*.gob.gt\",\n",
    "    \"El Salvador\": \"*.gob.sv\",\n",
    "    \"Honduras\": \"*.gob.hn\",\n",
    "    \"Nicaragua\": \"*.gob.ni\",\n",
    "    \"Belize\": \"*.gov.bz\",\n",
    "    \n",
    "    # South America\n",
    "    \"Brazil\": \"*.gov.br\",\n",
    "    \"Argentina\": \"*.gob.ar\",\n",
    "    \"Chile\": \"*.gob.cl\",\n",
    "    \"Colombia\": \"*.gov.co\",\n",
    "    \"Peru\": \"*.gob.pe\",\n",
    "    \"Venezuela\": \"*.gob.ve\",\n",
    "    \"Ecuador\": \"*.gob.ec\",\n",
    "    \"Bolivia\": \"*.gob.bo\",\n",
    "    \"Paraguay\": \"*.gov.py\",\n",
    "    \"Uruguay\": \"*.gub.uy\",\n",
    "    \"Guyana\": \"*.gov.gy\",\n",
    "    \"Suriname\": \"*.gov.sr\",\n",
    "    \n",
    "    # Western Europe\n",
    "    \"United Kingdom\": \"*.gov.uk\",\n",
    "    \"France\": \"*.gouv.fr\",\n",
    "    \"Germany\": [\"*.bund.de\", \"*.bayern.de\"],\n",
    "    \"Italy\": \"*.gov.it\",\n",
    "    \"Spain\": \"*.gob.es\",\n",
    "    \"Portugal\": \"*.gov.pt\",\n",
    "    \"Netherlands\": [\"*.overheid.nl\", \"*.regering.nl\"],\n",
    "    \"Belgium\": [\"*.belgium.be\", \"*.fed.be\"],\n",
    "    \"Ireland\": \"*.gov.ie\",\n",
    "    \"Luxembourg\": \"*.gouvernement.lu\",\n",
    "    \"Monaco\": \"*.gouv.mc\",\n",
    "    \n",
    "    # Northern Europe\n",
    "    \"Sweden\": [\"*.regeringen.se\", \"*.gov.se\"],\n",
    "    \"Norway\": \"*.regjeringen.no\",\n",
    "    \"Denmark\": \"*.gov.dk\",\n",
    "    \"Finland\": \"*.gov.fi\",\n",
    "    \"Iceland\": \"*.island.is\",\n",
    "    \"Estonia\": \"*.gov.ee\",\n",
    "    \"Latvia\": \"*.gov.lv\",\n",
    "    \"Lithuania\": \"*.gov.lt\",\n",
    "    \n",
    "    # Eastern Europe\n",
    "    \"Poland\": \"*.gov.pl\",\n",
    "    \"Czech Republic\": \"*.gov.cz\",\n",
    "    \"Slovakia\": \"*.gov.sk\",\n",
    "    \"Hungary\": \"*.gov.hu\",\n",
    "    \"Romania\": \"*.gov.ro\",\n",
    "    \"Bulgaria\": \"*.government.bg\",\n",
    "    \"Moldova\": \"*.gov.md\",\n",
    "    \"Ukraine\": \"*.gov.ua\",\n",
    "    \"Belarus\": \"*.gov.by\",\n",
    "    \n",
    "    # Southern Europe\n",
    "    \"Greece\": \"*.gov.gr\",\n",
    "    \"Croatia\": \"*.gov.hr\",\n",
    "    \"Serbia\": \"*.gov.rs\",\n",
    "    \"Slovenia\": \"*.gov.si\",\n",
    "    \"Albania\": \"*.gov.al\",\n",
    "    \"North Macedonia\": \"*.gov.mk\",\n",
    "    \"Bosnia and Herzegovina\": \"*.gov.ba\",\n",
    "    \"Montenegro\": \"*.gov.me\",\n",
    "    \"Malta\": \"*.gov.mt\",\n",
    "    \"Cyprus\": \"*.gov.cy\",\n",
    "    \n",
    "    # South Asia\n",
    "    \"India\": [\"*.gov.in\", \"*.nic.in\"],\n",
    "    \"Pakistan\": \"*.gov.pk\",\n",
    "    \"Bangladesh\": \"*.gov.bd\",\n",
    "    \"Sri Lanka\": \"*.gov.lk\",\n",
    "    \"Nepal\": \"*.gov.np\",\n",
    "    \"Bhutan\": \"*.gov.bt\",\n",
    "    \"Maldives\": \"*.gov.mv\",\n",
    "    \"Afghanistan\": \"*.gov.af\",\n",
    "    \n",
    "    # East Asia\n",
    "    \"Japan\": \"*.go.jp\",\n",
    "    \"South Korea\": \"*.go.kr\",\n",
    "    \"North Korea\": \"*.gov.kp\",\n",
    "    \"China\": [\"*.gov.cn\", \"*.政务.cn\"],\n",
    "    \"Mongolia\": \"*.gov.mn\",\n",
    "    \"Taiwan\": \"*.gov.tw\",\n",
    "\n",
    "    # Southeast Asia\n",
    "    \"Indonesia\": \"*.go.id\",\n",
    "    \"Malaysia\": \"*.gov.my\",\n",
    "    \"Singapore\": \"*.gov.sg\",\n",
    "    \"Philippines\": \"*.gov.ph\",\n",
    "    \"Thailand\": \"*.go.th\",\n",
    "    \"Vietnam\": \"*.gov.vn\",\n",
    "    \"Myanmar\": \"*.gov.mm\",\n",
    "    \"Cambodia\": \"*.gov.kh\",\n",
    "    \"Laos\": \"*.gov.la\",\n",
    "    \"Brunei\": \"*.gov.bn\",\n",
    "    \"Timor-Leste\": \"*.gov.tl\",\n",
    "    \n",
    "    # Central Asia\n",
    "    \"Kazakhstan\": \"*.gov.kz\",\n",
    "    \"Uzbekistan\": \"*.gov.uz\",\n",
    "    \"Kyrgyzstan\": \"*.gov.kg\",\n",
    "    \"Tajikistan\": \"*.gov.tj\",\n",
    "    \"Turkmenistan\": \"*.gov.tm\",\n",
    "    \n",
    "    # Middle East\n",
    "    \"Saudi Arabia\": \"*.gov.sa\",\n",
    "    \"UAE\": \"*.gov.ae\",\n",
    "    \"Iran\": \"*.gov.ir\",\n",
    "    \"Iraq\": \"*.gov.iq\",\n",
    "    \"Israel\": \"*.gov.il\",\n",
    "    \"Jordan\": \"*.gov.jo\",\n",
    "    \"Lebanon\": \"*.gov.lb\",\n",
    "    \"Oman\": \"*.gov.om\",\n",
    "    \"Qatar\": \"*.gov.qa\",\n",
    "    \"Kuwait\": \"*.gov.kw\",\n",
    "    \"Bahrain\": \"*.gov.bh\",\n",
    "    \"Yemen\": \"*.gov.ye\",\n",
    "    \"Syria\": \"*.gov.sy\",\n",
    "    \n",
    "    # North Africa\n",
    "    \"Egypt\": \"*.gov.eg\",\n",
    "    \"Morocco\": \"*.gov.ma\",\n",
    "    \"Tunisia\": \"*.gov.tn\",\n",
    "    \"Algeria\": \"*.gov.dz\",\n",
    "    \"Libya\": \"*.gov.ly\",\n",
    "    \"Sudan\": \"*.gov.sd\",\n",
    "    \n",
    "    # West Africa\n",
    "    \"Nigeria\": \"*.gov.ng\",\n",
    "    \"Ghana\": \"*.gov.gh\",\n",
    "    \"Senegal\": \"*.gouv.sn\",\n",
    "    \"Ivory Coast\": \"*.gouv.ci\",\n",
    "    \"Mali\": \"*.gouv.ml\",\n",
    "    \"Burkina Faso\": \"*.gov.bf\",\n",
    "    \"Guinea\": \"*.gov.gn\",\n",
    "    \"Sierra Leone\": \"*.gov.sl\",\n",
    "    \"Liberia\": \"*.gov.lr\",\n",
    "    \"Togo\": \"*.gouv.tg\",\n",
    "    \"Benin\": \"*.gouv.bj\",\n",
    "    \"Niger\": \"*.gouv.ne\",\n",
    "    \"Gambia\": \"*.gov.gm\",\n",
    "    \"Guinea-Bissau\": \"*.gov.gw\",\n",
    "    \"Cape Verde\": \"*.gov.cv\",\n",
    "    \n",
    "    # East Africa\n",
    "    \"Kenya\": \"*.go.ke\",\n",
    "    \"Tanzania\": \"*.go.tz\",\n",
    "    \"Uganda\": \"*.go.ug\",\n",
    "    \"Ethiopia\": \"*.gov.et\",\n",
    "    \"Rwanda\": \"*.gov.rw\",\n",
    "    \"Burundi\": \"*.gov.bi\",\n",
    "    \"South Sudan\": \"*.gov.ss\",\n",
    "    \"Eritrea\": \"*.gov.er\",\n",
    "    \"Djibouti\": \"*.gouv.dj\",\n",
    "    \"Somalia\": \"*.gov.so\",\n",
    "    \n",
    "    # Southern Africa\n",
    "    \"South Africa\": \"*.gov.za\",\n",
    "    \"Namibia\": \"*.gov.na\",\n",
    "    \"Botswana\": \"*.gov.bw\",\n",
    "    \"Zimbabwe\": \"*.gov.zw\",\n",
    "    \"Mozambique\": \"*.gov.mz\",\n",
    "    \"Zambia\": \"*.gov.zm\",\n",
    "    \"Malawi\": \"*.gov.mw\",\n",
    "    \"Angola\": \"*.gov.ao\",\n",
    "    \"Madagascar\": \"*.gov.mg\",\n",
    "    \"Mauritius\": \"*.gov.mu\",\n",
    "    \"Seychelles\": \"*.gov.sc\",\n",
    "    \"Lesotho\": \"*.gov.ls\",\n",
    "    \"Eswatini\": \"*.gov.sz\",\n",
    "    \n",
    "    # Oceania\n",
    "    \"Australia\": \"*.gov.au\",\n",
    "    \"New Zealand\": \"*.govt.nz\",\n",
    "    \"Papua New Guinea\": \"*.gov.pg\",\n",
    "    \"Fiji\": \"*.gov.fj\",\n",
    "    \"Solomon Islands\": \"*.gov.sb\",\n",
    "    \"Vanuatu\": \"*.gov.vu\",\n",
    "    \"New Caledonia\": \"*.gouv.nc\",\n",
    "    \"Samoa\": \"*.gov.ws\",\n",
    "    \"Tonga\": \"*.gov.to\",\n",
    "    \"French Polynesia\": \"*.gouv.pf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e28bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 20:43:59,730 - INFO - File commoncrawl_united states_ALL_gov_results.parquet already exists; skipping scrape for United States pattern *.gov\n",
      "2025-02-18 20:43:59,731 - INFO - File commoncrawl_united states_ALL_mil_results.parquet already exists; skipping scrape for United States pattern *.mil\n",
      "2025-02-18 20:43:59,731 - INFO - File commoncrawl_canada_ALL_gc_ca_results.parquet already exists; skipping scrape for Canada pattern *.gc.ca\n",
      "2025-02-18 20:43:59,731 - INFO - File commoncrawl_canada_ALL_canada_ca_results.parquet already exists; skipping scrape for Canada pattern *.canada.ca\n",
      "2025-02-18 20:43:59,732 - INFO - File commoncrawl_mexico_ALL_gob_mx_results.parquet already exists; skipping scrape for Mexico pattern *.gob.mx\n",
      "2025-02-18 20:43:59,732 - INFO - File commoncrawl_jamaica_ALL_gov_jm_results.parquet already exists; skipping scrape for Jamaica pattern *.gov.jm\n",
      "2025-02-18 20:43:59,732 - INFO - File commoncrawl_trinidad and tobago_ALL_gov_tt_results.parquet already exists; skipping scrape for Trinidad and Tobago pattern *.gov.tt\n",
      "2025-02-18 20:43:59,732 - INFO - File commoncrawl_barbados_ALL_gov_bb_results.parquet already exists; skipping scrape for Barbados pattern *.gov.bb\n",
      "2025-02-18 20:43:59,732 - INFO - File commoncrawl_bahamas_ALL_gov_bs_results.parquet already exists; skipping scrape for Bahamas pattern *.gov.bs\n",
      "2025-02-18 20:43:59,733 - INFO - File commoncrawl_dominican republic_ALL_gob_do_results.parquet already exists; skipping scrape for Dominican Republic pattern *.gob.do\n",
      "2025-02-18 20:43:59,733 - INFO - File commoncrawl_costa rica_ALL_go_cr_results.parquet already exists; skipping scrape for Costa Rica pattern *.go.cr\n",
      "2025-02-18 20:43:59,733 - INFO - File commoncrawl_panama_ALL_gob_pa_results.parquet already exists; skipping scrape for Panama pattern *.gob.pa\n",
      "2025-02-18 20:43:59,733 - INFO - File commoncrawl_guatemala_ALL_gob_gt_results.parquet already exists; skipping scrape for Guatemala pattern *.gob.gt\n",
      "2025-02-18 20:43:59,734 - INFO - File commoncrawl_el salvador_ALL_gob_sv_results.parquet already exists; skipping scrape for El Salvador pattern *.gob.sv\n",
      "2025-02-18 20:43:59,734 - INFO - File commoncrawl_honduras_ALL_gob_hn_results.parquet already exists; skipping scrape for Honduras pattern *.gob.hn\n",
      "2025-02-18 20:43:59,735 - INFO - File commoncrawl_nicaragua_ALL_gob_ni_results.parquet already exists; skipping scrape for Nicaragua pattern *.gob.ni\n",
      "2025-02-18 20:43:59,736 - INFO - File commoncrawl_belize_ALL_gov_bz_results.parquet already exists; skipping scrape for Belize pattern *.gov.bz\n",
      "2025-02-18 20:43:59,737 - INFO - File commoncrawl_brazil_ALL_gov_br_results.parquet already exists; skipping scrape for Brazil pattern *.gov.br\n",
      "2025-02-18 20:43:59,737 - INFO - File commoncrawl_argentina_ALL_gob_ar_results.parquet already exists; skipping scrape for Argentina pattern *.gob.ar\n",
      "2025-02-18 20:43:59,737 - INFO - File commoncrawl_chile_ALL_gob_cl_results.parquet already exists; skipping scrape for Chile pattern *.gob.cl\n",
      "2025-02-18 20:43:59,738 - INFO - File commoncrawl_colombia_ALL_gov_co_results.parquet already exists; skipping scrape for Colombia pattern *.gov.co\n",
      "2025-02-18 20:43:59,739 - INFO - File commoncrawl_peru_ALL_gob_pe_results.parquet already exists; skipping scrape for Peru pattern *.gob.pe\n",
      "2025-02-18 20:43:59,739 - INFO - File commoncrawl_venezuela_ALL_gob_ve_results.parquet already exists; skipping scrape for Venezuela pattern *.gob.ve\n",
      "2025-02-18 20:43:59,740 - INFO - File commoncrawl_ecuador_ALL_gob_ec_results.parquet already exists; skipping scrape for Ecuador pattern *.gob.ec\n",
      "2025-02-18 20:43:59,740 - INFO - File commoncrawl_bolivia_ALL_gob_bo_results.parquet already exists; skipping scrape for Bolivia pattern *.gob.bo\n",
      "2025-02-18 20:43:59,741 - INFO - File commoncrawl_paraguay_ALL_gov_py_results.parquet already exists; skipping scrape for Paraguay pattern *.gov.py\n",
      "2025-02-18 20:43:59,741 - INFO - File commoncrawl_uruguay_ALL_gub_uy_results.parquet already exists; skipping scrape for Uruguay pattern *.gub.uy\n",
      "2025-02-18 20:43:59,742 - INFO - File commoncrawl_guyana_ALL_gov_gy_results.parquet already exists; skipping scrape for Guyana pattern *.gov.gy\n",
      "2025-02-18 20:43:59,742 - INFO - File commoncrawl_suriname_ALL_gov_sr_results.parquet already exists; skipping scrape for Suriname pattern *.gov.sr\n",
      "2025-02-18 20:43:59,742 - INFO - File commoncrawl_united kingdom_ALL_gov_uk_results.parquet already exists; skipping scrape for United Kingdom pattern *.gov.uk\n",
      "2025-02-18 20:43:59,743 - INFO - File commoncrawl_france_ALL_gouv_fr_results.parquet already exists; skipping scrape for France pattern *.gouv.fr\n",
      "2025-02-18 20:43:59,743 - INFO - File commoncrawl_germany_ALL_bund_de_results.parquet already exists; skipping scrape for Germany pattern *.bund.de\n",
      "2025-02-18 20:43:59,744 - INFO - File commoncrawl_germany_ALL_bayern_de_results.parquet already exists; skipping scrape for Germany pattern *.bayern.de\n",
      "2025-02-18 20:43:59,745 - INFO - File commoncrawl_italy_ALL_gov_it_results.parquet already exists; skipping scrape for Italy pattern *.gov.it\n",
      "2025-02-18 20:43:59,746 - INFO - File commoncrawl_spain_ALL_gob_es_results.parquet already exists; skipping scrape for Spain pattern *.gob.es\n",
      "2025-02-18 20:43:59,747 - INFO - File commoncrawl_portugal_ALL_gov_pt_results.parquet already exists; skipping scrape for Portugal pattern *.gov.pt\n",
      "2025-02-18 20:43:59,747 - INFO - File commoncrawl_netherlands_ALL_overheid_nl_results.parquet already exists; skipping scrape for Netherlands pattern *.overheid.nl\n",
      "2025-02-18 20:43:59,748 - INFO - File commoncrawl_netherlands_ALL_regering_nl_results.parquet already exists; skipping scrape for Netherlands pattern *.regering.nl\n",
      "2025-02-18 20:43:59,748 - INFO - File commoncrawl_belgium_ALL_belgium_be_results.parquet already exists; skipping scrape for Belgium pattern *.belgium.be\n",
      "2025-02-18 20:43:59,748 - INFO - File commoncrawl_belgium_ALL_fed_be_results.parquet already exists; skipping scrape for Belgium pattern *.fed.be\n",
      "2025-02-18 20:43:59,749 - INFO - File commoncrawl_ireland_ALL_gov_ie_results.parquet already exists; skipping scrape for Ireland pattern *.gov.ie\n",
      "2025-02-18 20:43:59,749 - INFO - File commoncrawl_luxembourg_ALL_gouvernement_lu_results.parquet already exists; skipping scrape for Luxembourg pattern *.gouvernement.lu\n",
      "2025-02-18 20:43:59,749 - INFO - File commoncrawl_monaco_ALL_gouv_mc_results.parquet already exists; skipping scrape for Monaco pattern *.gouv.mc\n",
      "2025-02-18 20:43:59,750 - INFO - File commoncrawl_sweden_ALL_regeringen_se_results.parquet already exists; skipping scrape for Sweden pattern *.regeringen.se\n",
      "2025-02-18 20:43:59,750 - INFO - File commoncrawl_sweden_ALL_gov_se_results.parquet already exists; skipping scrape for Sweden pattern *.gov.se\n",
      "2025-02-18 20:43:59,750 - INFO - File commoncrawl_norway_ALL_regjeringen_no_results.parquet already exists; skipping scrape for Norway pattern *.regjeringen.no\n",
      "2025-02-18 20:43:59,751 - INFO - File commoncrawl_denmark_ALL_gov_dk_results.parquet already exists; skipping scrape for Denmark pattern *.gov.dk\n",
      "2025-02-18 20:43:59,752 - INFO - File commoncrawl_finland_ALL_gov_fi_results.parquet already exists; skipping scrape for Finland pattern *.gov.fi\n",
      "2025-02-18 20:43:59,752 - INFO - File commoncrawl_iceland_ALL_island_is_results.parquet already exists; skipping scrape for Iceland pattern *.island.is\n",
      "2025-02-18 20:43:59,753 - INFO - File commoncrawl_estonia_ALL_gov_ee_results.parquet already exists; skipping scrape for Estonia pattern *.gov.ee\n",
      "2025-02-18 20:43:59,753 - INFO - File commoncrawl_latvia_ALL_gov_lv_results.parquet already exists; skipping scrape for Latvia pattern *.gov.lv\n",
      "2025-02-18 20:43:59,753 - INFO - File commoncrawl_lithuania_ALL_gov_lt_results.parquet already exists; skipping scrape for Lithuania pattern *.gov.lt\n",
      "2025-02-18 20:43:59,754 - INFO - File commoncrawl_poland_ALL_gov_pl_results.parquet already exists; skipping scrape for Poland pattern *.gov.pl\n",
      "2025-02-18 20:43:59,754 - INFO - File commoncrawl_czech republic_ALL_gov_cz_results.parquet already exists; skipping scrape for Czech Republic pattern *.gov.cz\n",
      "2025-02-18 20:43:59,755 - INFO - File commoncrawl_slovakia_ALL_gov_sk_results.parquet already exists; skipping scrape for Slovakia pattern *.gov.sk\n",
      "2025-02-18 20:43:59,755 - INFO - File commoncrawl_hungary_ALL_gov_hu_results.parquet already exists; skipping scrape for Hungary pattern *.gov.hu\n",
      "2025-02-18 20:43:59,755 - INFO - File commoncrawl_romania_ALL_gov_ro_results.parquet already exists; skipping scrape for Romania pattern *.gov.ro\n",
      "2025-02-18 20:43:59,755 - INFO - File commoncrawl_bulgaria_ALL_government_bg_results.parquet already exists; skipping scrape for Bulgaria pattern *.government.bg\n",
      "2025-02-18 20:43:59,756 - INFO - File commoncrawl_moldova_ALL_gov_md_results.parquet already exists; skipping scrape for Moldova pattern *.gov.md\n",
      "2025-02-18 20:43:59,756 - INFO - File commoncrawl_ukraine_ALL_gov_ua_results.parquet already exists; skipping scrape for Ukraine pattern *.gov.ua\n",
      "2025-02-18 20:43:59,756 - INFO - File commoncrawl_belarus_ALL_gov_by_results.parquet already exists; skipping scrape for Belarus pattern *.gov.by\n",
      "2025-02-18 20:43:59,757 - INFO - File commoncrawl_greece_ALL_gov_gr_results.parquet already exists; skipping scrape for Greece pattern *.gov.gr\n",
      "2025-02-18 20:43:59,758 - INFO - File commoncrawl_croatia_ALL_gov_hr_results.parquet already exists; skipping scrape for Croatia pattern *.gov.hr\n",
      "2025-02-18 20:43:59,758 - INFO - File commoncrawl_serbia_ALL_gov_rs_results.parquet already exists; skipping scrape for Serbia pattern *.gov.rs\n",
      "2025-02-18 20:43:59,759 - INFO - File commoncrawl_slovenia_ALL_gov_si_results.parquet already exists; skipping scrape for Slovenia pattern *.gov.si\n",
      "2025-02-18 20:43:59,759 - INFO - File commoncrawl_albania_ALL_gov_al_results.parquet already exists; skipping scrape for Albania pattern *.gov.al\n",
      "2025-02-18 20:43:59,760 - INFO - File commoncrawl_north macedonia_ALL_gov_mk_results.parquet already exists; skipping scrape for North Macedonia pattern *.gov.mk\n",
      "2025-02-18 20:43:59,760 - INFO - File commoncrawl_bosnia and herzegovina_ALL_gov_ba_results.parquet already exists; skipping scrape for Bosnia and Herzegovina pattern *.gov.ba\n",
      "2025-02-18 20:43:59,761 - INFO - File commoncrawl_montenegro_ALL_gov_me_results.parquet already exists; skipping scrape for Montenegro pattern *.gov.me\n",
      "2025-02-18 20:43:59,762 - INFO - File commoncrawl_malta_ALL_gov_mt_results.parquet already exists; skipping scrape for Malta pattern *.gov.mt\n",
      "2025-02-18 20:43:59,764 - INFO - File commoncrawl_cyprus_ALL_gov_cy_results.parquet already exists; skipping scrape for Cyprus pattern *.gov.cy\n",
      "2025-02-18 20:43:59,764 - INFO - File commoncrawl_india_ALL_gov_in_results.parquet already exists; skipping scrape for India pattern *.gov.in\n",
      "2025-02-18 20:43:59,764 - INFO - File commoncrawl_india_ALL_nic_in_results.parquet already exists; skipping scrape for India pattern *.nic.in\n",
      "2025-02-18 20:43:59,765 - INFO - File commoncrawl_pakistan_ALL_gov_pk_results.parquet already exists; skipping scrape for Pakistan pattern *.gov.pk\n",
      "2025-02-18 20:43:59,765 - INFO - File commoncrawl_bangladesh_ALL_gov_bd_results.parquet already exists; skipping scrape for Bangladesh pattern *.gov.bd\n",
      "2025-02-18 20:43:59,766 - INFO - File commoncrawl_sri lanka_ALL_gov_lk_results.parquet already exists; skipping scrape for Sri Lanka pattern *.gov.lk\n",
      "2025-02-18 20:43:59,766 - INFO - File commoncrawl_nepal_ALL_gov_np_results.parquet already exists; skipping scrape for Nepal pattern *.gov.np\n",
      "2025-02-18 20:43:59,766 - INFO - File commoncrawl_bhutan_ALL_gov_bt_results.parquet already exists; skipping scrape for Bhutan pattern *.gov.bt\n",
      "2025-02-18 20:43:59,767 - INFO - File commoncrawl_maldives_ALL_gov_mv_results.parquet already exists; skipping scrape for Maldives pattern *.gov.mv\n",
      "2025-02-18 20:43:59,768 - INFO - Starting scrape for Afghanistan pattern: *.gov.af\n",
      "2025-02-18 20:43:59,768 - INFO - Starting scrape for Afghanistan pattern: *.gov.af\n",
      "2025-02-18 20:43:59,769 - INFO - Fetching page 0 for *.gov.af\n",
      "2025-02-18 20:44:04,160 - INFO - Page 0 returned 13166 results.\n",
      "2025-02-18 20:44:04,163 - INFO - Scraped page 0 for Afghanistan pattern *.gov.af (13166 results). Total pages scraped: 1\n",
      "2025-02-18 20:44:04,164 - INFO - Sleeping for 1.11 seconds before next page request.\n",
      "2025-02-18 20:44:05,281 - INFO - Fetching page 1 for *.gov.af\n",
      "2025-02-18 20:44:05,385 - ERROR - Error fetching page 1 for *.gov.af: 400 Client Error: Bad Request for url: https://index.commoncrawl.org/CC-MAIN-2024-30-index?url=%2A.gov.af&output=json&page=1\n",
      "2025-02-18 20:44:05,386 - INFO - No more results for Afghanistan pattern *.gov.af after page 1.\n",
      "2025-02-18 20:44:05,386 - INFO - Finished scraping pattern *.gov.af for Afghanistan. Total results: 13166\n",
      "2025-02-18 20:44:06,317 - INFO - Saved intermediate results for Afghanistan pattern *.gov.af to commoncrawl_afghanistan_ALL_gov_af_results.parquet\n",
      "2025-02-18 20:44:06,317 - INFO - File commoncrawl_japan_ALL_go_jp_results.parquet already exists; skipping scrape for Japan pattern *.go.jp\n",
      "2025-02-18 20:44:06,318 - INFO - File commoncrawl_south korea_ALL_go_kr_results.parquet already exists; skipping scrape for South Korea pattern *.go.kr\n",
      "2025-02-18 20:44:06,318 - INFO - File commoncrawl_north korea_ALL_gov_kp_results.parquet already exists; skipping scrape for North Korea pattern *.gov.kp\n",
      "2025-02-18 20:44:06,318 - INFO - File commoncrawl_china_ALL_gov_cn_results.parquet already exists; skipping scrape for China pattern *.gov.cn\n",
      "2025-02-18 20:44:06,319 - INFO - Starting scrape for China pattern: *.政务.cn\n",
      "2025-02-18 20:44:06,319 - INFO - Starting scrape for China pattern: *.政务.cn\n",
      "2025-02-18 20:44:06,320 - INFO - Fetching page 0 for *.政务.cn\n",
      "2025-02-18 20:44:06,625 - ERROR - Error fetching page 0 for *.政务.cn: 404 Client Error: Not Found for url: https://index.commoncrawl.org/CC-MAIN-2024-30-index?url=%2A.%E6%94%BF%E5%8A%A1.cn&output=json&page=0\n",
      "2025-02-18 20:44:06,627 - INFO - No more results for China pattern *.政务.cn after page 0.\n",
      "2025-02-18 20:44:06,628 - INFO - Finished scraping pattern *.政务.cn for China. Total results: 0\n",
      "2025-02-18 20:44:06,630 - INFO - No data found for China pattern *.政务.cn.\n",
      "2025-02-18 20:44:06,632 - INFO - File commoncrawl_mongolia_ALL_gov_mn_results.parquet already exists; skipping scrape for Mongolia pattern *.gov.mn\n",
      "2025-02-18 20:44:06,635 - INFO - File commoncrawl_taiwan_ALL_gov_tw_results.parquet already exists; skipping scrape for Taiwan pattern *.gov.tw\n",
      "2025-02-18 20:44:06,637 - INFO - File commoncrawl_indonesia_ALL_go_id_results.parquet already exists; skipping scrape for Indonesia pattern *.go.id\n",
      "2025-02-18 20:44:06,638 - INFO - File commoncrawl_malaysia_ALL_gov_my_results.parquet already exists; skipping scrape for Malaysia pattern *.gov.my\n",
      "2025-02-18 20:44:06,640 - INFO - File commoncrawl_singapore_ALL_gov_sg_results.parquet already exists; skipping scrape for Singapore pattern *.gov.sg\n",
      "2025-02-18 20:44:06,643 - INFO - File commoncrawl_philippines_ALL_gov_ph_results.parquet already exists; skipping scrape for Philippines pattern *.gov.ph\n",
      "2025-02-18 20:44:06,644 - INFO - File commoncrawl_thailand_ALL_go_th_results.parquet already exists; skipping scrape for Thailand pattern *.go.th\n",
      "2025-02-18 20:44:06,646 - INFO - File commoncrawl_vietnam_ALL_gov_vn_results.parquet already exists; skipping scrape for Vietnam pattern *.gov.vn\n",
      "2025-02-18 20:44:06,647 - INFO - File commoncrawl_myanmar_ALL_gov_mm_results.parquet already exists; skipping scrape for Myanmar pattern *.gov.mm\n",
      "2025-02-18 20:44:06,649 - INFO - File commoncrawl_cambodia_ALL_gov_kh_results.parquet already exists; skipping scrape for Cambodia pattern *.gov.kh\n",
      "2025-02-18 20:44:06,650 - INFO - File commoncrawl_laos_ALL_gov_la_results.parquet already exists; skipping scrape for Laos pattern *.gov.la\n",
      "2025-02-18 20:44:06,651 - INFO - File commoncrawl_brunei_ALL_gov_bn_results.parquet already exists; skipping scrape for Brunei pattern *.gov.bn\n",
      "2025-02-18 20:44:06,651 - INFO - File commoncrawl_timor-leste_ALL_gov_tl_results.parquet already exists; skipping scrape for Timor-Leste pattern *.gov.tl\n",
      "2025-02-18 20:44:06,651 - INFO - File commoncrawl_kazakhstan_ALL_gov_kz_results.parquet already exists; skipping scrape for Kazakhstan pattern *.gov.kz\n",
      "2025-02-18 20:44:06,652 - INFO - File commoncrawl_uzbekistan_ALL_gov_uz_results.parquet already exists; skipping scrape for Uzbekistan pattern *.gov.uz\n",
      "2025-02-18 20:44:06,652 - INFO - File commoncrawl_kyrgyzstan_ALL_gov_kg_results.parquet already exists; skipping scrape for Kyrgyzstan pattern *.gov.kg\n",
      "2025-02-18 20:44:06,652 - INFO - File commoncrawl_tajikistan_ALL_gov_tj_results.parquet already exists; skipping scrape for Tajikistan pattern *.gov.tj\n",
      "2025-02-18 20:44:06,653 - INFO - File commoncrawl_turkmenistan_ALL_gov_tm_results.parquet already exists; skipping scrape for Turkmenistan pattern *.gov.tm\n",
      "2025-02-18 20:44:06,653 - INFO - File commoncrawl_saudi arabia_ALL_gov_sa_results.parquet already exists; skipping scrape for Saudi Arabia pattern *.gov.sa\n",
      "2025-02-18 20:44:06,654 - INFO - File commoncrawl_uae_ALL_gov_ae_results.parquet already exists; skipping scrape for UAE pattern *.gov.ae\n",
      "2025-02-18 20:44:06,654 - INFO - File commoncrawl_iran_ALL_gov_ir_results.parquet already exists; skipping scrape for Iran pattern *.gov.ir\n",
      "2025-02-18 20:44:06,655 - INFO - File commoncrawl_iraq_ALL_gov_iq_results.parquet already exists; skipping scrape for Iraq pattern *.gov.iq\n",
      "2025-02-18 20:44:06,655 - INFO - File commoncrawl_israel_ALL_gov_il_results.parquet already exists; skipping scrape for Israel pattern *.gov.il\n",
      "2025-02-18 20:44:06,656 - INFO - File commoncrawl_jordan_ALL_gov_jo_results.parquet already exists; skipping scrape for Jordan pattern *.gov.jo\n",
      "2025-02-18 20:44:06,656 - INFO - File commoncrawl_lebanon_ALL_gov_lb_results.parquet already exists; skipping scrape for Lebanon pattern *.gov.lb\n",
      "2025-02-18 20:44:06,656 - INFO - File commoncrawl_oman_ALL_gov_om_results.parquet already exists; skipping scrape for Oman pattern *.gov.om\n",
      "2025-02-18 20:44:06,657 - INFO - File commoncrawl_qatar_ALL_gov_qa_results.parquet already exists; skipping scrape for Qatar pattern *.gov.qa\n",
      "2025-02-18 20:44:06,657 - INFO - File commoncrawl_kuwait_ALL_gov_kw_results.parquet already exists; skipping scrape for Kuwait pattern *.gov.kw\n",
      "2025-02-18 20:44:06,658 - INFO - File commoncrawl_bahrain_ALL_gov_bh_results.parquet already exists; skipping scrape for Bahrain pattern *.gov.bh\n",
      "2025-02-18 20:44:06,658 - INFO - File commoncrawl_yemen_ALL_gov_ye_results.parquet already exists; skipping scrape for Yemen pattern *.gov.ye\n",
      "2025-02-18 20:44:06,659 - INFO - File commoncrawl_syria_ALL_gov_sy_results.parquet already exists; skipping scrape for Syria pattern *.gov.sy\n",
      "2025-02-18 20:44:06,659 - INFO - File commoncrawl_egypt_ALL_gov_eg_results.parquet already exists; skipping scrape for Egypt pattern *.gov.eg\n",
      "2025-02-18 20:44:06,659 - INFO - File commoncrawl_morocco_ALL_gov_ma_results.parquet already exists; skipping scrape for Morocco pattern *.gov.ma\n",
      "2025-02-18 20:44:06,660 - INFO - File commoncrawl_tunisia_ALL_gov_tn_results.parquet already exists; skipping scrape for Tunisia pattern *.gov.tn\n",
      "2025-02-18 20:44:06,660 - INFO - File commoncrawl_algeria_ALL_gov_dz_results.parquet already exists; skipping scrape for Algeria pattern *.gov.dz\n",
      "2025-02-18 20:44:06,660 - INFO - File commoncrawl_libya_ALL_gov_ly_results.parquet already exists; skipping scrape for Libya pattern *.gov.ly\n",
      "2025-02-18 20:44:06,661 - INFO - File commoncrawl_sudan_ALL_gov_sd_results.parquet already exists; skipping scrape for Sudan pattern *.gov.sd\n",
      "2025-02-18 20:44:06,661 - INFO - File commoncrawl_nigeria_ALL_gov_ng_results.parquet already exists; skipping scrape for Nigeria pattern *.gov.ng\n",
      "2025-02-18 20:44:06,661 - INFO - File commoncrawl_ghana_ALL_gov_gh_results.parquet already exists; skipping scrape for Ghana pattern *.gov.gh\n",
      "2025-02-18 20:44:06,662 - INFO - File commoncrawl_senegal_ALL_gouv_sn_results.parquet already exists; skipping scrape for Senegal pattern *.gouv.sn\n",
      "2025-02-18 20:44:06,663 - INFO - File commoncrawl_ivory coast_ALL_gouv_ci_results.parquet already exists; skipping scrape for Ivory Coast pattern *.gouv.ci\n",
      "2025-02-18 20:44:06,663 - INFO - File commoncrawl_mali_ALL_gouv_ml_results.parquet already exists; skipping scrape for Mali pattern *.gouv.ml\n",
      "2025-02-18 20:44:06,664 - INFO - File commoncrawl_burkina faso_ALL_gov_bf_results.parquet already exists; skipping scrape for Burkina Faso pattern *.gov.bf\n",
      "2025-02-18 20:44:06,664 - INFO - File commoncrawl_guinea_ALL_gov_gn_results.parquet already exists; skipping scrape for Guinea pattern *.gov.gn\n",
      "2025-02-18 20:44:06,665 - INFO - File commoncrawl_sierra leone_ALL_gov_sl_results.parquet already exists; skipping scrape for Sierra Leone pattern *.gov.sl\n",
      "2025-02-18 20:44:06,665 - INFO - File commoncrawl_liberia_ALL_gov_lr_results.parquet already exists; skipping scrape for Liberia pattern *.gov.lr\n",
      "2025-02-18 20:44:06,665 - INFO - File commoncrawl_togo_ALL_gouv_tg_results.parquet already exists; skipping scrape for Togo pattern *.gouv.tg\n",
      "2025-02-18 20:44:06,666 - INFO - File commoncrawl_benin_ALL_gouv_bj_results.parquet already exists; skipping scrape for Benin pattern *.gouv.bj\n",
      "2025-02-18 20:44:06,666 - INFO - File commoncrawl_niger_ALL_gouv_ne_results.parquet already exists; skipping scrape for Niger pattern *.gouv.ne\n",
      "2025-02-18 20:44:06,667 - INFO - File commoncrawl_gambia_ALL_gov_gm_results.parquet already exists; skipping scrape for Gambia pattern *.gov.gm\n",
      "2025-02-18 20:44:06,667 - INFO - File commoncrawl_guinea-bissau_ALL_gov_gw_results.parquet already exists; skipping scrape for Guinea-Bissau pattern *.gov.gw\n",
      "2025-02-18 20:44:06,667 - INFO - File commoncrawl_cape verde_ALL_gov_cv_results.parquet already exists; skipping scrape for Cape Verde pattern *.gov.cv\n",
      "2025-02-18 20:44:06,668 - INFO - File commoncrawl_kenya_ALL_go_ke_results.parquet already exists; skipping scrape for Kenya pattern *.go.ke\n",
      "2025-02-18 20:44:06,669 - INFO - File commoncrawl_tanzania_ALL_go_tz_results.parquet already exists; skipping scrape for Tanzania pattern *.go.tz\n",
      "2025-02-18 20:44:06,669 - INFO - File commoncrawl_uganda_ALL_go_ug_results.parquet already exists; skipping scrape for Uganda pattern *.go.ug\n",
      "2025-02-18 20:44:06,669 - INFO - File commoncrawl_ethiopia_ALL_gov_et_results.parquet already exists; skipping scrape for Ethiopia pattern *.gov.et\n",
      "2025-02-18 20:44:06,670 - INFO - File commoncrawl_rwanda_ALL_gov_rw_results.parquet already exists; skipping scrape for Rwanda pattern *.gov.rw\n",
      "2025-02-18 20:44:06,670 - INFO - File commoncrawl_burundi_ALL_gov_bi_results.parquet already exists; skipping scrape for Burundi pattern *.gov.bi\n",
      "2025-02-18 20:44:06,670 - INFO - File commoncrawl_south sudan_ALL_gov_ss_results.parquet already exists; skipping scrape for South Sudan pattern *.gov.ss\n",
      "2025-02-18 20:44:06,671 - INFO - Starting scrape for Eritrea pattern: *.gov.er\n",
      "2025-02-18 20:44:06,671 - INFO - Starting scrape for Eritrea pattern: *.gov.er\n",
      "2025-02-18 20:44:06,672 - INFO - Fetching page 0 for *.gov.er\n",
      "2025-02-18 20:44:07,165 - ERROR - Error fetching page 0 for *.gov.er: 404 Client Error: Not Found for url: https://index.commoncrawl.org/CC-MAIN-2024-30-index?url=%2A.gov.er&output=json&page=0\n",
      "2025-02-18 20:44:07,166 - INFO - No more results for Eritrea pattern *.gov.er after page 0.\n",
      "2025-02-18 20:44:07,167 - INFO - Finished scraping pattern *.gov.er for Eritrea. Total results: 0\n",
      "2025-02-18 20:44:07,169 - INFO - No data found for Eritrea pattern *.gov.er.\n",
      "2025-02-18 20:44:07,171 - INFO - File commoncrawl_djibouti_ALL_gouv_dj_results.parquet already exists; skipping scrape for Djibouti pattern *.gouv.dj\n",
      "2025-02-18 20:44:07,172 - INFO - File commoncrawl_somalia_ALL_gov_so_results.parquet already exists; skipping scrape for Somalia pattern *.gov.so\n",
      "2025-02-18 20:44:07,174 - INFO - File commoncrawl_south africa_ALL_gov_za_results.parquet already exists; skipping scrape for South Africa pattern *.gov.za\n",
      "2025-02-18 20:44:07,175 - INFO - File commoncrawl_namibia_ALL_gov_na_results.parquet already exists; skipping scrape for Namibia pattern *.gov.na\n",
      "2025-02-18 20:44:07,176 - INFO - File commoncrawl_botswana_ALL_gov_bw_results.parquet already exists; skipping scrape for Botswana pattern *.gov.bw\n",
      "2025-02-18 20:44:07,178 - INFO - File commoncrawl_zimbabwe_ALL_gov_zw_results.parquet already exists; skipping scrape for Zimbabwe pattern *.gov.zw\n",
      "2025-02-18 20:44:07,179 - INFO - File commoncrawl_mozambique_ALL_gov_mz_results.parquet already exists; skipping scrape for Mozambique pattern *.gov.mz\n",
      "2025-02-18 20:44:07,180 - INFO - File commoncrawl_zambia_ALL_gov_zm_results.parquet already exists; skipping scrape for Zambia pattern *.gov.zm\n",
      "2025-02-18 20:44:07,181 - INFO - File commoncrawl_malawi_ALL_gov_mw_results.parquet already exists; skipping scrape for Malawi pattern *.gov.mw\n",
      "2025-02-18 20:44:07,182 - INFO - File commoncrawl_angola_ALL_gov_ao_results.parquet already exists; skipping scrape for Angola pattern *.gov.ao\n",
      "2025-02-18 20:44:07,183 - INFO - File commoncrawl_madagascar_ALL_gov_mg_results.parquet already exists; skipping scrape for Madagascar pattern *.gov.mg\n",
      "2025-02-18 20:44:07,185 - INFO - Starting scrape for Mauritius pattern: *.gov.mu\n",
      "2025-02-18 20:44:07,185 - INFO - Starting scrape for Mauritius pattern: *.gov.mu\n",
      "2025-02-18 20:44:07,186 - INFO - Fetching page 0 for *.gov.mu\n",
      "2025-02-18 20:44:07,526 - ERROR - Error fetching page 0 for *.gov.mu: 404 Client Error: Not Found for url: https://index.commoncrawl.org/CC-MAIN-2024-30-index?url=%2A.gov.mu&output=json&page=0\n",
      "2025-02-18 20:44:07,527 - INFO - No more results for Mauritius pattern *.gov.mu after page 0.\n",
      "2025-02-18 20:44:07,530 - INFO - Finished scraping pattern *.gov.mu for Mauritius. Total results: 0\n",
      "2025-02-18 20:44:07,533 - INFO - No data found for Mauritius pattern *.gov.mu.\n",
      "2025-02-18 20:44:07,534 - INFO - File commoncrawl_seychelles_ALL_gov_sc_results.parquet already exists; skipping scrape for Seychelles pattern *.gov.sc\n",
      "2025-02-18 20:44:07,535 - INFO - File commoncrawl_lesotho_ALL_gov_ls_results.parquet already exists; skipping scrape for Lesotho pattern *.gov.ls\n",
      "2025-02-18 20:44:07,536 - INFO - File commoncrawl_eswatini_ALL_gov_sz_results.parquet already exists; skipping scrape for Eswatini pattern *.gov.sz\n",
      "2025-02-18 20:44:07,538 - INFO - File commoncrawl_australia_ALL_gov_au_results.parquet already exists; skipping scrape for Australia pattern *.gov.au\n",
      "2025-02-18 20:44:07,540 - INFO - File commoncrawl_new zealand_ALL_govt_nz_results.parquet already exists; skipping scrape for New Zealand pattern *.govt.nz\n",
      "2025-02-18 20:44:07,542 - INFO - File commoncrawl_papua new guinea_ALL_gov_pg_results.parquet already exists; skipping scrape for Papua New Guinea pattern *.gov.pg\n",
      "2025-02-18 20:44:07,543 - INFO - File commoncrawl_fiji_ALL_gov_fj_results.parquet already exists; skipping scrape for Fiji pattern *.gov.fj\n",
      "2025-02-18 20:44:07,544 - INFO - File commoncrawl_solomon islands_ALL_gov_sb_results.parquet already exists; skipping scrape for Solomon Islands pattern *.gov.sb\n",
      "2025-02-18 20:44:07,546 - INFO - File commoncrawl_vanuatu_ALL_gov_vu_results.parquet already exists; skipping scrape for Vanuatu pattern *.gov.vu\n",
      "2025-02-18 20:44:07,547 - INFO - File commoncrawl_new caledonia_ALL_gouv_nc_results.parquet already exists; skipping scrape for New Caledonia pattern *.gouv.nc\n",
      "2025-02-18 20:44:07,548 - INFO - File commoncrawl_samoa_ALL_gov_ws_results.parquet already exists; skipping scrape for Samoa pattern *.gov.ws\n",
      "2025-02-18 20:44:07,548 - INFO - File commoncrawl_tonga_ALL_gov_to_results.parquet already exists; skipping scrape for Tonga pattern *.gov.to\n",
      "2025-02-18 20:44:07,550 - INFO - Starting scrape for French Polynesia pattern: *.gouv.pf\n",
      "2025-02-18 20:44:07,550 - INFO - Starting scrape for French Polynesia pattern: *.gouv.pf\n",
      "2025-02-18 20:44:07,551 - INFO - Fetching page 0 for *.gouv.pf\n",
      "2025-02-18 20:44:07,933 - ERROR - Error fetching page 0 for *.gouv.pf: 404 Client Error: Not Found for url: https://index.commoncrawl.org/CC-MAIN-2024-30-index?url=%2A.gouv.pf&output=json&page=0\n",
      "2025-02-18 20:44:07,934 - INFO - No more results for French Polynesia pattern *.gouv.pf after page 0.\n",
      "2025-02-18 20:44:07,934 - INFO - Finished scraping pattern *.gouv.pf for French Polynesia. Total results: 0\n",
      "2025-02-18 20:44:07,935 - INFO - No data found for French Polynesia pattern *.gouv.pf.\n",
      "2025-02-18 20:44:08,039 - INFO - Scrape complete. Total results: 13166. Saved final results to commoncrawl_all_results.parquet\n",
      "2025-02-18 20:44:08,048 - INFO - Summary of results by country and pattern:\n",
      "2025-02-18 20:44:08,050 - INFO -     country  pattern  count\n",
      "Afghanistan *.gov.af  13166\n"
     ]
    }
   ],
   "source": [
    "scraper = CommonCrawlScraper()\n",
    "\n",
    "df = scraper.scrape_all(gov_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19983b6c-cc3e-4bb7-83eb-2629b8a8fba8",
   "metadata": {},
   "source": [
    "### Upload to Harvard Dataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9935f1c-c589-418c-99e7-41797c3a59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing files in dataset: ['commoncrawl_albania_ALL_gov_al_results.parquet', 'commoncrawl_argentina_ALL_gob_ar_results.parquet', 'commoncrawl_barbados_ALL_gov_bb_results.parquet', 'commoncrawl_belgium_ALL_belgium_be_results.parquet', 'commoncrawl_belize_ALL_gov_bz_results.parquet', 'commoncrawl_benin_ALL_gouv_bj_results.parquet', 'commoncrawl_botswana_ALL_gov_bw_results.parquet', 'commoncrawl_brazil_ALL_gov_br_results.parquet', 'commoncrawl_bulgaria_ALL_government_bg_results.parquet', 'commoncrawl_burkina faso_ALL_gov_bf_results.parquet', 'commoncrawl_cambodia_ALL_gov_kh_results.parquet', 'commoncrawl_canada_ALL_canada_ca_results.parquet', 'commoncrawl_canada_ALL_gc_ca_results.parquet', 'commoncrawl_china_ALL_gov_cn_results.parquet', 'commoncrawl_croatia_ALL_gov_hr_results.parquet', 'commoncrawl_czech republic_ALL_gov_cz_results.parquet', 'commoncrawl_denmark_ALL_gov_dk_results.parquet', 'commoncrawl_djibouti_ALL_gouv_dj_results.parquet', 'commoncrawl_estonia_ALL_gov_ee_results.parquet', 'commoncrawl_ethiopia_ALL_gov_et_results.parquet', 'commoncrawl_germany_ALL_bayern_de_results.parquet', 'commoncrawl_germany_ALL_bund_de_results.parquet', 'commoncrawl_greece_ALL_gov_gr_results.parquet', 'commoncrawl_guyana_ALL_gov_gy_results.parquet', 'commoncrawl_hungary_ALL_gov_hu_results.parquet', 'commoncrawl_iran_ALL_gov_ir_results.parquet', 'commoncrawl_ireland_ALL_gov_ie_results.parquet', 'commoncrawl_israel_ALL_gov_il_results.parquet', 'commoncrawl_ivory coast_ALL_gouv_ci_results.parquet', 'commoncrawl_japan_ALL_go_jp_results.parquet', 'commoncrawl_kazakhstan_ALL_gov_kz_results.parquet', 'commoncrawl_laos_ALL_gov_la_results.parquet', 'commoncrawl_latvia_ALL_gov_lv_results.parquet', 'commoncrawl_liberia_ALL_gov_lr_results.parquet', 'commoncrawl_libya_ALL_gov_ly_results.parquet', 'commoncrawl_lithuania_ALL_gov_lt_results.parquet', 'commoncrawl_luxembourg_ALL_gouvernement_lu_results.parquet', 'commoncrawl_malawi_ALL_gov_mw_results.parquet', 'commoncrawl_mali_ALL_gouv_ml_results.parquet', 'commoncrawl_mexico_ALL_gob_mx_results.parquet', 'commoncrawl_moldova_ALL_gov_md_results.parquet', 'commoncrawl_monaco_ALL_gouv_mc_results.parquet', 'commoncrawl_montenegro_ALL_gov_me_results.parquet', 'commoncrawl_morocco_ALL_gov_ma_results.parquet', 'commoncrawl_netherlands_ALL_overheid_nl_results.parquet', 'commoncrawl_new caledonia_ALL_gouv_nc_results.parquet', 'commoncrawl_new zealand_ALL_govt_nz_results.parquet', 'commoncrawl_norway_ALL_regjeringen_no_results.parquet', 'commoncrawl_panama_ALL_gob_pa_results.parquet', 'commoncrawl_peru_ALL_gob_pe_results.parquet', 'commoncrawl_qatar_ALL_gov_qa_results.parquet', 'commoncrawl_romania_ALL_gov_ro_results.parquet', 'commoncrawl_sierra leone_ALL_gov_sl_results.parquet', 'commoncrawl_singapore_ALL_gov_sg_results.parquet', 'commoncrawl_slovakia_ALL_gov_sk_results.parquet', 'commoncrawl_slovenia_ALL_gov_si_results.parquet', 'commoncrawl_solomon islands_ALL_gov_sb_results.parquet', 'commoncrawl_somalia_ALL_gov_so_results.parquet', 'commoncrawl_south africa_ALL_gov_za_results.parquet', 'commoncrawl_south sudan_ALL_gov_ss_results.parquet', 'commoncrawl_spain_ALL_gob_es_results.parquet', 'commoncrawl_suriname_ALL_gov_sr_results.parquet', 'commoncrawl_sweden_ALL_gov_se_results.parquet', 'commoncrawl_sweden_ALL_regeringen_se_results.parquet', 'commoncrawl_taiwan_ALL_gov_tw_results.parquet', 'commoncrawl_tanzania_ALL_go_tz_results.parquet', 'commoncrawl_togo_ALL_gouv_tg_results.parquet', 'commoncrawl_united kingdom_ALL_gov_uk_results.parquet', 'commoncrawl_united states_ALL_mil_results.parquet', 'commoncrawl_uruguay_ALL_gub_uy_results.parquet', 'commoncrawl_venezuela_ALL_gob_ve_results.parquet', 'commoncrawl_zambia_ALL_gov_zm_results.parquet']\n",
      "Uploading: commoncrawl_afghanistan_ALL_gov_af_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_albania_ALL_gov_al_results.parquet\n",
      "Uploading: commoncrawl_algeria_ALL_gov_dz_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_all_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_angola_ALL_gov_ao_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_argentina_ALL_gob_ar_results.parquet\n",
      "Uploading: commoncrawl_australia_ALL_gov_aus_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_bahamas_ALL_gov_bs_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_bahrain_ALL_gov_bh_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_bangladesh_ALL_gov_bd_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_barbados_ALL_gov_bb_results.parquet\n",
      "Uploading: commoncrawl_belarus_ALL_gov_by_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_belgium_ALL_belgium_be_results.parquet\n",
      "Uploading: commoncrawl_belgium_ALL_fed_be_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_belize_ALL_gov_bz_results.parquet\n",
      "File already exists, skipping: commoncrawl_benin_ALL_gouv_bj_results.parquet\n",
      "Uploading: commoncrawl_bhutan_ALL_gov_bt_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_bolivia_ALL_gob_bo_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_bosnia and herzegovina_ALL_gov_ba_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_botswana_ALL_gov_bw_results.parquet\n",
      "File already exists, skipping: commoncrawl_brazil_ALL_gov_br_results.parquet\n",
      "Uploading: commoncrawl_brunei_ALL_gov_bn_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_bulgaria_ALL_government_bg_results.parquet\n",
      "File already exists, skipping: commoncrawl_burkina faso_ALL_gov_bf_results.parquet\n",
      "Uploading: commoncrawl_burundi_ALL_gov_bi_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_cambodia_ALL_gov_kh_results.parquet\n",
      "File already exists, skipping: commoncrawl_canada_ALL_canada_ca_results.parquet\n",
      "File already exists, skipping: commoncrawl_canada_ALL_gc_ca_results.parquet\n",
      "Uploading: commoncrawl_cape verde_ALL_gov_cv_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_chile_ALL_gob_cl_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_china_ALL_gov_cn_results.parquet\n",
      "Uploading: commoncrawl_colombia_ALL_gov_co_results.parquet\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/944808875.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;34m\"jsonData\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Send empty JSON metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         }\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Status code:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"user-agent\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1284\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{len(chunk):X}\\r\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0;34mb'\\r\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencode_chunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36msendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0mamount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to send() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "API_KEY = \"945730d0-ef77-4c33-b67a-1165e79519ea\"\n",
    "DATAVERSE_URL = \"https://dataverse.harvard.edu\"\n",
    "doi = \"doi:10.7910/DVN/NKHAKM\"  # Your dataset persistent ID\n",
    "folder_path = Path(\".\")\n",
    "\n",
    "# Set headers for authentication\n",
    "headers = {\"X-Dataverse-key\": API_KEY}\n",
    "\n",
    "# URL to fetch dataset metadata (to get existing file names)\n",
    "metadata_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId?persistentId={quote(doi)}\"\n",
    "\n",
    "def get_existing_file_labels():\n",
    "    response = requests.get(metadata_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error getting dataset metadata:\", response.status_code)\n",
    "        return []\n",
    "    try:\n",
    "        data = response.json()[\"data\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON metadata:\", e)\n",
    "        return []\n",
    "    # Navigate to the latest version; file info is usually stored in the \"files\" list.\n",
    "    latest_version = data.get(\"latestVersion\", {})\n",
    "    files = latest_version.get(\"files\", [])\n",
    "    # Extract file names. Dataverse may store the filename in \"dataFile\" or as \"label\".\n",
    "    labels = []\n",
    "    for f in files:\n",
    "        if \"dataFile\" in f and f[\"dataFile\"].get(\"filename\"):\n",
    "            labels.append(f[\"dataFile\"][\"filename\"])\n",
    "        elif \"label\" in f:\n",
    "            labels.append(f[\"label\"])\n",
    "    return labels\n",
    "\n",
    "# Retrieve existing file names in the dataset\n",
    "existing_files = get_existing_file_labels()\n",
    "print(\"Existing files in dataset:\", existing_files)\n",
    "\n",
    "# Build the upload URL using the persistentId endpoint\n",
    "upload_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId/add?persistentId={quote(doi)}\"\n",
    "\n",
    "# Loop over all Parquet files in the folder\n",
    "for fn in sorted(folder_path.glob(\"*.parquet\")):\n",
    "    if fn.name in existing_files:\n",
    "        print(\"File already exists, skipping:\", fn.name)\n",
    "        continue\n",
    "    print(\"Uploading:\", fn.name)\n",
    "    with fn.open(\"rb\") as f:\n",
    "        files = {\n",
    "            \"file\": (fn.name, f, \"application/octet-stream\"),\n",
    "            \"jsonData\": (None, \"{}\")  # Send empty JSON metadata\n",
    "        }\n",
    "        response = requests.post(upload_url, headers=headers, files=files)\n",
    "    \n",
    "    print(\"Status code:\", response.status_code)\n",
    "    print(\"Response text:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a30970-ae8b-4a5c-bce0-a9605d9d4e4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Api' object has no attribute 'get_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/654667936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Retrieve existing file names in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mexisting_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_existing_file_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Existing files in dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/654667936.py\u001b[0m in \u001b[0;36mget_existing_file_labels\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_existing_file_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmetadata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{DATAVERSE_URL}/api/datasets/:persistentId?persistentId={quote(doi)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error getting dataset metadata:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Api' object has no attribute 'get_dataset'"
     ]
    }
   ],
   "source": [
    "from pyDataverse.api import Api\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Configuration\n",
    "API_KEY = \"945730d0-ef77-4c33-b67a-1165e79519ea\"\n",
    "DATAVERSE_URL = \"https://dataverse.harvard.edu\"\n",
    "doi = \"doi:10.7910/DVN/NKHAKM\"  # Dataset persistent ID (include the \"doi:\" prefix)\n",
    "folder_path = Path(\".\")\n",
    "\n",
    "# Instantiate the API client with the API token passed as a constructor argument\n",
    "api = Api(DATAVERSE_URL, api_token=API_KEY)\n",
    "\n",
    "# Function to retrieve existing file labels from the dataset metadata\n",
    "def get_existing_file_labels():\n",
    "    metadata_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId?persistentId={quote(doi)}\"\n",
    "    resp = api.get_dataset(doi)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Error getting dataset metadata:\", resp.status_code)\n",
    "        return []\n",
    "    try:\n",
    "        data = resp.json()[\"data\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON metadata:\", e)\n",
    "        return []\n",
    "    latest_version = data.get(\"latestVersion\", {})\n",
    "    files = latest_version.get(\"files\", [])\n",
    "    labels = []\n",
    "    for f in files:\n",
    "        if \"dataFile\" in f and f[\"dataFile\"].get(\"filename\"):\n",
    "            labels.append(f[\"dataFile\"][\"filename\"])\n",
    "        elif \"label\" in f:\n",
    "            labels.append(f[\"label\"])\n",
    "    return labels\n",
    "\n",
    "# Retrieve existing file names in the dataset\n",
    "existing_files = get_existing_file_labels()\n",
    "print(\"Existing files in dataset:\", existing_files)\n",
    "\n",
    "# Build the upload URL using the persistentId endpoint\n",
    "upload_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId/add?persistentId={quote(doi)}\"\n",
    "\n",
    "# Loop over all Parquet files in the folder and upload those not already present\n",
    "for fn in sorted(folder_path.glob(\"*.parquet\")):\n",
    "    if fn.name in existing_files:\n",
    "        print(\"File already exists, skipping:\", fn.name)\n",
    "        continue\n",
    "    print(\"Uploading:\", fn.name)\n",
    "    with fn.open(\"rb\") as f:\n",
    "        files = {\n",
    "            \"file\": (fn.name, f, \"application/octet-stream\"),\n",
    "            \"jsonData\": (None, \"{}\")  # Provide an empty JSON object for metadata\n",
    "        }\n",
    "        resp = api.upload_file(doi, str(fn), json_str=\"{}\")\n",
    "    print(\"Status code:\", resp.status_code)\n",
    "    print(\"Response text:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628e5b31-52b4-496c-abf2-a2c8c6fa7d09",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Api' object has no attribute 'get_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/654667936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Retrieve existing file names in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mexisting_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_existing_file_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Existing files in dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/654667936.py\u001b[0m in \u001b[0;36mget_existing_file_labels\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_existing_file_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmetadata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{DATAVERSE_URL}/api/datasets/:persistentId?persistentId={quote(doi)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error getting dataset metadata:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Api' object has no attribute 'get_dataset'"
     ]
    }
   ],
   "source": [
    "from pyDataverse.api import Api\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Configuration\n",
    "API_KEY = \"945730d0-ef77-4c33-b67a-1165e79519ea\"\n",
    "DATAVERSE_URL = \"https://dataverse.harvard.edu\"\n",
    "doi = \"doi:10.7910/DVN/NKHAKM\"  # Dataset persistent ID (include the \"doi:\" prefix)\n",
    "folder_path = Path(\".\")\n",
    "\n",
    "# Instantiate the API client with the API token passed as a constructor argument\n",
    "api = Api(DATAVERSE_URL, api_token=API_KEY)\n",
    "\n",
    "# Function to retrieve existing file labels from the dataset metadata\n",
    "def get_existing_file_labels():\n",
    "    metadata_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId?persistentId={quote(doi)}\"\n",
    "    resp = api.get_dataset(doi)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Error getting dataset metadata:\", resp.status_code)\n",
    "        return []\n",
    "    try:\n",
    "        data = resp.json()[\"data\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON metadata:\", e)\n",
    "        return []\n",
    "    latest_version = data.get(\"latestVersion\", {})\n",
    "    files = latest_version.get(\"files\", [])\n",
    "    labels = []\n",
    "    for f in files:\n",
    "        if \"dataFile\" in f and f[\"dataFile\"].get(\"filename\"):\n",
    "            labels.append(f[\"dataFile\"][\"filename\"])\n",
    "        elif \"label\" in f:\n",
    "            labels.append(f[\"label\"])\n",
    "    return labels\n",
    "\n",
    "# Retrieve existing file names in the dataset\n",
    "existing_files = get_existing_file_labels()\n",
    "print(\"Existing files in dataset:\", existing_files)\n",
    "\n",
    "# Build the upload URL using the persistentId endpoint\n",
    "upload_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId/add?persistentId={quote(doi)}\"\n",
    "\n",
    "# Loop over all Parquet files in the folder and upload those not already present\n",
    "for fn in sorted(folder_path.glob(\"*.parquet\")):\n",
    "    if fn.name in existing_files:\n",
    "        print(\"File already exists, skipping:\", fn.name)\n",
    "        continue\n",
    "    print(\"Uploading:\", fn.name)\n",
    "    with fn.open(\"rb\") as f:\n",
    "        files = {\n",
    "            \"file\": (fn.name, f, \"application/octet-stream\"),\n",
    "            \"jsonData\": (None, \"{}\")  # Provide an empty JSON object for metadata\n",
    "        }\n",
    "        resp = api.upload_file(doi, str(fn), json_str=\"{}\")\n",
    "    print(\"Status code:\", resp.status_code)\n",
    "    print(\"Response text:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17af2311-aec8-46e6-b4c2-baaf9de254b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing files in dataset: ['commoncrawl_albania_ALL_gov_al_results.parquet', 'commoncrawl_argentina_ALL_gob_ar_results.parquet', 'commoncrawl_barbados_ALL_gov_bb_results.parquet', 'commoncrawl_belgium_ALL_belgium_be_results.parquet', 'commoncrawl_belize_ALL_gov_bz_results.parquet', 'commoncrawl_benin_ALL_gouv_bj_results.parquet', 'commoncrawl_botswana_ALL_gov_bw_results.parquet', 'commoncrawl_brazil_ALL_gov_br_results.parquet', 'commoncrawl_bulgaria_ALL_government_bg_results.parquet', 'commoncrawl_burkina faso_ALL_gov_bf_results.parquet', 'commoncrawl_cambodia_ALL_gov_kh_results.parquet', 'commoncrawl_canada_ALL_canada_ca_results.parquet', 'commoncrawl_canada_ALL_gc_ca_results.parquet', 'commoncrawl_china_ALL_gov_cn_results.parquet', 'commoncrawl_croatia_ALL_gov_hr_results.parquet', 'commoncrawl_czech republic_ALL_gov_cz_results.parquet', 'commoncrawl_denmark_ALL_gov_dk_results.parquet', 'commoncrawl_djibouti_ALL_gouv_dj_results.parquet', 'commoncrawl_estonia_ALL_gov_ee_results.parquet', 'commoncrawl_ethiopia_ALL_gov_et_results.parquet', 'commoncrawl_germany_ALL_bayern_de_results.parquet', 'commoncrawl_germany_ALL_bund_de_results.parquet', 'commoncrawl_greece_ALL_gov_gr_results.parquet', 'commoncrawl_guyana_ALL_gov_gy_results.parquet', 'commoncrawl_hungary_ALL_gov_hu_results.parquet', 'commoncrawl_iran_ALL_gov_ir_results.parquet', 'commoncrawl_ireland_ALL_gov_ie_results.parquet', 'commoncrawl_israel_ALL_gov_il_results.parquet', 'commoncrawl_ivory coast_ALL_gouv_ci_results.parquet', 'commoncrawl_japan_ALL_go_jp_results.parquet', 'commoncrawl_kazakhstan_ALL_gov_kz_results.parquet', 'commoncrawl_laos_ALL_gov_la_results.parquet', 'commoncrawl_latvia_ALL_gov_lv_results.parquet', 'commoncrawl_liberia_ALL_gov_lr_results.parquet', 'commoncrawl_libya_ALL_gov_ly_results.parquet', 'commoncrawl_lithuania_ALL_gov_lt_results.parquet', 'commoncrawl_luxembourg_ALL_gouvernement_lu_results.parquet', 'commoncrawl_malawi_ALL_gov_mw_results.parquet', 'commoncrawl_mali_ALL_gouv_ml_results.parquet', 'commoncrawl_mexico_ALL_gob_mx_results.parquet', 'commoncrawl_moldova_ALL_gov_md_results.parquet', 'commoncrawl_monaco_ALL_gouv_mc_results.parquet', 'commoncrawl_montenegro_ALL_gov_me_results.parquet', 'commoncrawl_morocco_ALL_gov_ma_results.parquet', 'commoncrawl_netherlands_ALL_overheid_nl_results.parquet', 'commoncrawl_new caledonia_ALL_gouv_nc_results.parquet', 'commoncrawl_new zealand_ALL_govt_nz_results.parquet', 'commoncrawl_norway_ALL_regjeringen_no_results.parquet', 'commoncrawl_panama_ALL_gob_pa_results.parquet', 'commoncrawl_peru_ALL_gob_pe_results.parquet', 'commoncrawl_qatar_ALL_gov_qa_results.parquet', 'commoncrawl_romania_ALL_gov_ro_results.parquet', 'commoncrawl_sierra leone_ALL_gov_sl_results.parquet', 'commoncrawl_singapore_ALL_gov_sg_results.parquet', 'commoncrawl_slovakia_ALL_gov_sk_results.parquet', 'commoncrawl_slovenia_ALL_gov_si_results.parquet', 'commoncrawl_solomon islands_ALL_gov_sb_results.parquet', 'commoncrawl_somalia_ALL_gov_so_results.parquet', 'commoncrawl_south africa_ALL_gov_za_results.parquet', 'commoncrawl_south sudan_ALL_gov_ss_results.parquet', 'commoncrawl_spain_ALL_gob_es_results.parquet', 'commoncrawl_suriname_ALL_gov_sr_results.parquet', 'commoncrawl_sweden_ALL_gov_se_results.parquet', 'commoncrawl_sweden_ALL_regeringen_se_results.parquet', 'commoncrawl_taiwan_ALL_gov_tw_results.parquet', 'commoncrawl_tanzania_ALL_go_tz_results.parquet', 'commoncrawl_togo_ALL_gouv_tg_results.parquet', 'commoncrawl_united kingdom_ALL_gov_uk_results.parquet', 'commoncrawl_united states_ALL_mil_results.parquet', 'commoncrawl_uruguay_ALL_gub_uy_results.parquet', 'commoncrawl_venezuela_ALL_gob_ve_results.parquet', 'commoncrawl_zambia_ALL_gov_zm_results.parquet']\n",
      "Uploading: commoncrawl_afghanistan_ALL_gov_af_results.parquet\n",
      "api.upload_file failed for commoncrawl_afghanistan_ALL_gov_af_results.parquet with error: 'Api' object has no attribute 'upload_data'\n",
      "Falling back to direct requests.post...\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_albania_ALL_gov_al_results.parquet\n",
      "Uploading: commoncrawl_algeria_ALL_gov_dz_results.parquet\n",
      "api.upload_file failed for commoncrawl_algeria_ALL_gov_dz_results.parquet with error: 'Api' object has no attribute 'upload_data'\n",
      "Falling back to direct requests.post...\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_all_results.parquet\n",
      "api.upload_file failed for commoncrawl_all_results.parquet with error: 'Api' object has no attribute 'upload_data'\n",
      "Falling back to direct requests.post...\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_angola_ALL_gov_ao_results.parquet\n",
      "api.upload_file failed for commoncrawl_angola_ALL_gov_ao_results.parquet with error: 'Api' object has no attribute 'upload_data'\n",
      "Falling back to direct requests.post...\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File already exists, skipping: commoncrawl_argentina_ALL_gob_ar_results.parquet\n",
      "Uploading: commoncrawl_australia_ALL_gov_au_results.parquet\n",
      "api.upload_file failed for commoncrawl_australia_ALL_gov_au_results.parquet with error: 'Api' object has no attribute 'upload_data'\n",
      "Falling back to direct requests.post...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/3080309847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Api' object has no attribute 'upload_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/3080309847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"api.upload_file failed for {fn.name} with error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Falling back to direct requests.post...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_payload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Status code:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"user-agent\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1284\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{len(chunk):X}\\r\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0;34mb'\\r\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencode_chunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36msendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0mamount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to send() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "from pyDataverse.api import Api  # using Api, since NativeApi isn't available\n",
    "\n",
    "# Configuration\n",
    "API_KEY = \"945730d0-ef77-4c33-b67a-1165e79519ea\"\n",
    "DATAVERSE_URL = \"https://dataverse.harvard.edu\"\n",
    "doi = \"doi:10.7910/DVN/NKHAKM\"  # Dataset persistent ID (with \"doi:\" prefix)\n",
    "folder_path = Path(\".\")\n",
    "\n",
    "# Instantiate the API client, supplying the API token in the constructor if available.\n",
    "# (If your version doesn't support setting the token via the constructor,\n",
    "#  we can simply pass the token in our requests.)\n",
    "api = Api(DATAVERSE_URL, api_token=API_KEY)\n",
    "\n",
    "# Since your Api object doesn't offer get_dataset, we'll use requests directly\n",
    "headers = {\"X-Dataverse-key\": API_KEY}\n",
    "\n",
    "def get_existing_file_labels():\n",
    "    \"\"\"Fetch dataset metadata using the persistentId endpoint and return a list of existing file names.\"\"\"\n",
    "    metadata_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId?persistentId={quote(doi)}\"\n",
    "    resp = requests.get(metadata_url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Error getting dataset metadata:\", resp.status_code)\n",
    "        return []\n",
    "    try:\n",
    "        data = resp.json()[\"data\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON metadata:\", e)\n",
    "        return []\n",
    "    latest_version = data.get(\"latestVersion\", {})\n",
    "    files = latest_version.get(\"files\", [])\n",
    "    labels = []\n",
    "    for f in files:\n",
    "        if \"dataFile\" in f and f[\"dataFile\"].get(\"filename\"):\n",
    "            labels.append(f[\"dataFile\"][\"filename\"])\n",
    "        elif \"label\" in f:\n",
    "            labels.append(f[\"label\"])\n",
    "    return labels\n",
    "\n",
    "existing_files = get_existing_file_labels()\n",
    "print(\"Existing files in dataset:\", existing_files)\n",
    "\n",
    "# Build the upload URL using the persistentId endpoint\n",
    "upload_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId/add?persistentId={quote(doi)}\"\n",
    "\n",
    "# Loop over all Parquet files in the folder and upload those that do not already exist\n",
    "for fn in sorted(folder_path.glob(\"*.parquet\")):\n",
    "    if fn.name in existing_files:\n",
    "        print(\"File already exists, skipping:\", fn.name)\n",
    "        continue\n",
    "    print(\"Uploading:\", fn.name)\n",
    "    with fn.open(\"rb\") as f:\n",
    "        files_payload = {\n",
    "            \"file\": (fn.name, f, \"application/octet-stream\"),\n",
    "            \"jsonData\": (None, \"{}\")  # Provide an empty JSON object for metadata\n",
    "        }\n",
    "        # Using pyDataverse's upload_file if available; if not, fallback to requests\n",
    "        try:\n",
    "            resp = api.upload_data(doi, str(fn), json_str=\"{}\")\n",
    "        except Exception as e:\n",
    "            print(f\"api.upload_file failed for {fn.name} with error: {e}\")\n",
    "            print(\"Falling back to direct requests.post...\")\n",
    "            resp = requests.post(upload_url, headers=headers, files=files_payload)\n",
    "    \n",
    "    print(\"Status code:\", resp.status_code)\n",
    "    print(\"Response text:\", resp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "671db34f-d744-4df8-91c4-ebbd371f7119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file checksums in dataset: {'ab01e2d0af832c76b2d1173ffbb1b155', 'e43fc01546cdf1434b099fd5e2e4f588', '4b51852060c1882d8363b057d9bc7648', '6fd45dd490ad555bede0ada109584b4d', '10a32403670c8dd8e7c197414f327fe8', '649e404530c4b7ca07a9ad92d9c62db2', '43d632c74bc8b4083ea11b8201b0ad32', 'dc5780faf421d7d6463b954d806269af', '06dab45d62b2008e4e3a9c49118f3e55', '890ee1b47380a1526919c74977676652', '79ce9f110ac4a4fee8c56268c9e8979d', '36eacf7eb8acc06a44a9a334d6e95368', '25a701b7b6dbfc0a3f5ea08cc9be3540', 'c7b3e44899acd214e189625050894df5', 'baf650d3959d48d8373958cff131d379', 'cbcebade24e9e8896b60542b50ead644', 'e21a3ff2da1e494d9d308a682029e5db', '751a9d98fe5da2df15f22a225025e460', '471411ce5da6eaa861b222f8d8ee4da0', '7f2968f28658b9c129ff0fa776d3f855', 'b7c97d8346663e429f5ab065e57796ec', '6f79a9f443828da71e10ae557546f5eb', 'a2b9b4ec95033b72ef78d43b5b21ca75', '4a78560bfdb04e69ebe1e06778921d7f', '50a244af6656621f01df104d5576abf4', '8bf81f9091dfd2150772e31cb010b85c', '7c2ca81bf932010f81092ffd6e6e1151', '0a05866d6ae0cf52fbe7ae88e98a84e5', '132c16e0e69b222c4e4b2d533c9a7e36', '050b8eb7dbfd313398c77fd122f04112', 'b69ccd90fdeea3bf940163a015b684c5', '0d525905c38e8120fb02743c4fa8b987', 'c1c50407a9ad208294bce05f2d9223a1', '2af46a2955aaa804deb38488802f7dfc', '506df4584a472640f65040604b1c1a15', '32217d6fa16ae33124861a8fc3fa4ee0', 'e8cc744f337a3fbc34ae4372bcfdd7ae', '1166d39c845bfb70fcc62e01e1fdd42e', '028e94d55235ddd36f10f8ebd94133ff', '1eb70dc03e09721ed18d1ad04f11ab3b', '11da42cef49f7d1faa21474aebb6f050', 'cab7d08ced8cbe3750589b025d1d02b8', '320b87c336944ee8b671fa16fa15762c', 'e7f72c6d86ab850860ce32c5a88d33bb', '59d98c2ffa0d6c017446b94ef9db7a98', '4a94d7705a51775288a9672d24ce5297', 'e64defffc0e5aa640acbd36352ebc7c2', 'c8011b5308829e3d430a52506f566658', '4c551bc0315dbd2f5d4d6f4694e6a3ce', 'd84bac9a9358ffef2123ddb428c1dc14', '73cbd0195584116e8f1446b2aa4b662e', '7ac32748357e7fdafdc1821e1beb9d2d', '8bff75ba3e9c36163a7f473e36ec6d32', '49471752784b60116a693bcac15eb9c9', '0237223e98a819a4ab7af51db3192df7', 'a40a80ecfcae9dee5106f310ba405e26', 'd62b8762acb60641d9f85c4631c87721', 'ab3127446d0b5a92fced72aa4544114e', '66b08a8c944a652e239f73a575066aa2', '2c757a9e374e6e9fbdc17befe7af9829', '4bbc00edc8b778cc2d63cfae003de2f5', 'c05e45b381b4c9435eddd1db46cc1b00', '840c5f2428439f8355b23864230806db', 'c0b773ba822b93005479a55f5288bed1', '11c5ae24414cb02974ff0a7bab1e00ef', '1571796e44d9f97303f91fad4cf3373d', '4a2c4994d1520ab43a4d9541c3388d7d', 'fdd3afdee88d2d2de86e3a45e92e95fe', '104682610d0cd2d65485e343a7f04b59', 'ad857c4899900619ec06f84e9d4ff869', '073702975e6de0748659cc50f1d36764', 'ad872e854bdcfcd68044f147f6ab76c3'}\n",
      "Uploading: commoncrawl_afghanistan_ALL_gov_af_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Skipping commoncrawl_albania_ALL_gov_al_results.parquet (duplicate content; MD5: 10a32403670c8dd8e7c197414f327fe8).\n",
      "Uploading: commoncrawl_algeria_ALL_gov_dz_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_all_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Uploading: commoncrawl_angola_ALL_gov_ao_results.parquet\n",
      "Status code: 403\n",
      "Response text: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Skipping commoncrawl_argentina_ALL_gob_ar_results.parquet (duplicate content; MD5: c7b3e44899acd214e189625050894df5).\n",
      "Uploading: commoncrawl_australia_ALL_gov_au_results.parquet\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/ipykernel_65701/2247205353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;34m\"jsonData\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Uploaded via API\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         }\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_payload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Status code:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"user-agent\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1284\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{len(chunk):X}\\r\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0;34mb'\\r\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencode_chunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_vsn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36msendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0mamount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to send() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import hashlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "from pyDataverse.api import Api\n",
    "\n",
    "# Configuration\n",
    "API_KEY = \"945730d0-ef77-4c33-b67a-1165e79519ea\"\n",
    "DATAVERSE_URL = \"https://dataverse.harvard.edu\"\n",
    "doi = \"doi:10.7910/DVN/NKHAKM\"  # Your dataset persistent ID\n",
    "folder_path = Path(\".\")\n",
    "\n",
    "# Instantiate the API client (even if we don't use its methods, it shows we're using pyDataverse)\n",
    "api = Api(DATAVERSE_URL, api_token=API_KEY)\n",
    "\n",
    "# Set headers for direct requests\n",
    "headers = {\"X-Dataverse-key\": API_KEY}\n",
    "\n",
    "# Function to compute MD5 checksum of a file\n",
    "def md5_checksum(file_path, chunk_size=8192):\n",
    "    md5 = hashlib.md5()\n",
    "    with file_path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            md5.update(chunk)\n",
    "    return md5.hexdigest()\n",
    "\n",
    "# Retrieve dataset metadata using requests to get existing file checksums\n",
    "metadata_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId?persistentId={quote(doi)}\"\n",
    "resp = requests.get(metadata_url, headers=headers)\n",
    "if resp.status_code != 200:\n",
    "    print(\"Error retrieving dataset metadata:\", resp.status_code)\n",
    "    existing_checksums = set()\n",
    "else:\n",
    "    try:\n",
    "        data = resp.json().get(\"data\", {})\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON metadata:\", e)\n",
    "        data = {}\n",
    "    latest_version = data.get(\"latestVersion\", {})\n",
    "    files = latest_version.get(\"files\", [])\n",
    "    existing_checksums = set()\n",
    "    for f in files:\n",
    "        # Some Dataverse versions store the checksum under f[\"dataFile\"][\"checksum\"][\"value\"]\n",
    "        if \"dataFile\" in f and f[\"dataFile\"].get(\"checksum\", {}).get(\"value\"):\n",
    "            existing_checksums.add(f[\"dataFile\"][\"checksum\"][\"value\"])\n",
    "print(\"Existing file checksums in dataset:\", existing_checksums)\n",
    "\n",
    "# Build the upload URL using the persistentId endpoint\n",
    "upload_url = f\"{DATAVERSE_URL}/api/datasets/:persistentId/add?persistentId={quote(doi)}\"\n",
    "\n",
    "# Loop over all Parquet files in the folder\n",
    "for fn in sorted(folder_path.glob(\"*.parquet\")):\n",
    "    file_md5 = md5_checksum(fn)\n",
    "    if file_md5 in existing_checksums:\n",
    "        print(f\"Skipping {fn.name} (duplicate content; MD5: {file_md5}).\")\n",
    "        continue\n",
    "    print(\"Uploading:\", fn.name)\n",
    "    with fn.open(\"rb\") as f:\n",
    "        files_payload = {\n",
    "            \"file\": (fn.name, f, \"application/octet-stream\"),\n",
    "            \"jsonData\": (None, json.dumps({\"description\": \"Uploaded via API\"}))\n",
    "        }\n",
    "        response = requests.post(upload_url, headers=headers, files=files_payload)\n",
    "    \n",
    "    print(\"Status code:\", response.status_code)\n",
    "    print(\"Response text:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd8c60-05cb-4771-9933-4c575daa7211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
